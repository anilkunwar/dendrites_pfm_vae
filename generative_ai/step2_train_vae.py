import math
import os
import time
from datetime import datetime

import torch
import albumentations as A
import argparse
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from collections import defaultdict
import pandas as pd

from src.lossv2 import PhysicsConstrainedVAELoss
from src.dataloader import DendritePFMDataset
from src.modelv4 import VAE


def main(args):

    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # --------------------------
    # è¾“å‡ºç›®å½•
    # --------------------------
    exp_name = (
        f"V4_"
        f"noise{args.noise_prob}_"
        # f"edge{args.w_edge}_"
        f"kl{args.w_kl}_"
        f"tv{args.w_tv}_"
        f"smooth{args.w_smooth}_"
        f"grad{args.w_grad}_"
        f"{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    )

    save_root = os.path.join(args.fig_root, exp_name)
    os.makedirs(save_root, exist_ok=True)
    os.mkdir(os.path.join(save_root, "ckpt"))

    print("ğŸ“ å®éªŒç›®å½•:", save_root)

    # --------------------------
    # æ•°æ®é›†ï¼ˆåŠ å…¥åŠ¨æ€å™ªå£°ï¼‰
    # --------------------------
    train_dataset = DendritePFMDataset(
        args.image_size,
        os.path.join("data", "dataset_split.json"),
        split="train",
        transform=A.Compose([
            A.CoarseDropout(
                num_holes_range=(1, 8),
                hole_height_range=(0.01, 0.1),
                hole_width_range=(0.01, 0.1),
                p=0.1
            ),
            A.PixelDropout(dropout_prob=0.05, p=0.1),
            A.GaussNoise(p=args.noise_prob),
        ])
    )

    valid_dataset = DendritePFMDataset(
        args.image_size,
        os.path.join("data", "dataset_split.json"),
        split="test"
    )

    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=False)
    valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=False)

    # --------------------------
    # æ¨¡å‹
    # --------------------------
    vae = VAE(
        image_size=args.image_size,
        latent_size=args.latent_size,
        hidden_dimension=args.hidden_dimension,
        num_params=args.num_params
    ).to(device)

    # --------------------------
    # å¯è°ƒæƒé‡æŸå¤±
    # --------------------------
    loss_fn = PhysicsConstrainedVAELoss(
        w_kl=args.w_kl,
        w_tv=args.w_tv,
        w_smoothness=args.w_smooth,
        w_grad=args.w_grad
    )

    optimizer = torch.optim.Adam(vae.parameters(), lr=args.learning_rate)

    # --------------------------
    # æ—¥å¿—ç»“æ„ï¼ˆè®°å½•å…¨éƒ¨æŸå¤±ï¼‰
    # --------------------------
    logs = {
        "train": defaultdict(list),
        "valid": defaultdict(list)
    }

    best_val = float("inf")
    patience = 10
    no_imp = 0

    # ======================================================
    #                     è®­ç»ƒå¾ªç¯
    # ======================================================
    for epoch in range(args.epochs):

        # ==================================================
        #                     Train
        # ==================================================
        vae.train()
        for it, (x, y, did, xo) in enumerate(train_loader):
            x, y, xo = x.to(device), y.to(device), xo.to(device)
            recon_x, mean, log_var, z = vae(x, y)

            total_loss, loss_dict = loss_fn(recon_x.view(xo.shape), xo, mean, log_var)

            # ---- è®°å½•æŸå¤±ï¼ˆæ‰€æœ‰å­—æ®µï¼‰----
            for k, v in loss_dict.items():
                logs["train"][k].append(v if isinstance(v, float) else float(v))

            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()

            if it % args.print_every == 0:
                print(f"[Train] Epoch {epoch} It {it}/{len(train_loader)} Loss = {total_loss.item():.4f}")

        # ==================================================
        #                     Valid
        # ==================================================
        vae.eval()
        val_epoch_losses = []

        with torch.no_grad():
            for it, (x, y, did, xo) in enumerate(valid_loader):
                x, y, xo = x.to(device), y.to(device), xo.to(device)
                recon_x, mean, log_var, z = vae(x, y)

                total_loss, loss_dict = loss_fn(recon_x.view(xo.shape), xo, mean, log_var)

                # ---- è®°å½•æŸå¤±ï¼ˆæ‰€æœ‰å­—æ®µï¼‰----
                for k, v in loss_dict.items():
                    logs["valid"][k].append(v if isinstance(v, float) else float(v))

                val_epoch_losses.append(total_loss.item())

                # ------------------------------------
                # ä¿å­˜å›¾ç‰‡ï¼ˆä¿æŒåŸæ ·ï¼‰
                # ------------------------------------
                plt.figure()
                for p in range(min(9, recon_x.shape[0])):
                    plt.subplot(3, 3, p + 1)
                    plt.text(
                        0, 0, f"t={y[p][0].item()} did={did[p]}",
                        color='black', backgroundcolor='white', fontsize=8
                    )
                    plt.imshow(
                        recon_x[p].view(args.image_size)
                        .detach().cpu().numpy().transpose(1, 2, 0)
                    )
                    plt.axis("off")

                plt.savefig(os.path.join(save_root, f"E{epoch}_I{it}.png"), dpi=300)
                plt.close()

        avg_val = sum(val_epoch_losses) / len(val_epoch_losses)
        print(f"[Valid] Epoch {epoch} AvgLoss = {avg_val:.4f}")

        # ==================================================
        #                    Early Stopping
        # ==================================================
        if avg_val < best_val:
            best_val = avg_val
            no_imp = 0
            torch.save(vae, os.path.join(save_root, "ckpt", "CVAE.ckpt"))
            print("âœ” Model improved & saved")
        else:
            no_imp += 1
            print(f"No improvement {no_imp}/{patience}")

        if no_imp >= patience or math.isnan(avg_val):
            print("ğŸ›‘ Early stopping")
            break

        # ==================================================
        #               æ¯ä¸ª epoch ä¿å­˜æŸå¤±æ›²çº¿
        # ==================================================

        # --- train ---
        df_train = pd.DataFrame(logs["train"])
        df_train.to_csv(os.path.join(save_root, "train_loss.csv"), index=False)

        plt.figure()
        for k in df_train.columns:
            plt.plot(df_train[k], label=k)
        plt.legend()
        plt.title("Train Loss")
        plt.savefig(os.path.join(save_root, "train_loss.png"), dpi=300)
        plt.close()

        # --- valid ---
        df_valid = pd.DataFrame(logs["valid"])
        df_valid.to_csv(os.path.join(save_root, "valid_loss.csv"), index=False)

        plt.figure()
        for k in df_valid.columns:
            plt.plot(df_valid[k], label=k)
        plt.legend()
        plt.title("Valid Loss")
        plt.savefig(os.path.join(save_root, "valid_loss.png"), dpi=300)
        plt.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument("--seed", type=int, default=0)
    parser.add_argument("--epochs", type=int, default=1000)
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--learning_rate", type=float, default=1e-5)
    parser.add_argument("--image_size", type=tuple, default=(3, 64, 64))
    parser.add_argument("--hidden_dimension", type=int, default=512)
    parser.add_argument("--latent_size", type=int, default=128)
    parser.add_argument("--num_params", type=int, default=15)
    parser.add_argument("--print_every", type=int, default=10)

    # åŠ¨æ€å‚æ•°
    parser.add_argument("--noise_prob", type=float, default=0.1)
    # parser.add_argument("--w_edge", type=float, default=0.01)
    parser.add_argument("--w_kl", type=float, default=0.001)
    parser.add_argument("--w_tv", type=float, default=0)
    parser.add_argument("--w_smooth", type=float, default=0)
    parser.add_argument("--w_grad", type=float, default=1.0)

    parser.add_argument("--fig_root", type=str, default="results")

    args = parser.parse_args()
    main(args)
